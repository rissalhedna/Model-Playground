{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from model import UNet\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_data = MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "batch_size = 100 \n",
    "train_data_loader = DataLoader(train_data, batch_size = batch_size)\n",
    "test_data_loader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "for X, y in test_data_loader:\n",
    "    print(X.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAKSCAYAAABMVtaZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAL5ZJREFUeJzt3Qu01FXdP/59ABHwkssQEzNRyYBQM01LE1hpohZ5SbMM06LCMh9d6qOB4AVCy0t5YZnxpGGGaWL6iKsyrQTNu2ZeSU1FFFHwhigiwvzXTD/7P+Z3H5nDcL7nzOf1WsulfjZ7vptzZp95nz2z97elUqlUEgAATa9L2QMAAKB9CH4AAEEIfgAAQQh+AABBCH4AAEEIfgAAQQh+AABBCH4AAEEIfgAAQQh+AABBCH4dwNKlS9Pxxx+f+vbtm3r27Jl23HHHdP3115c9LGhK99xzT/rCF76Q1l9//dSrV680ePDgdO6555Y9LGgaDz74YDrggAPS5ptvXptjvXv3TkOGDEkzZswoe2iklLqVPQBSOvTQQ9P06dPTUUcdlT784Q+nqVOnpr322iv95S9/SZ/+9KfLHh40jT/+8Y9pxIgRadttt03jx49Pa6+9dvrnP/+Znn766bKHBk1jzpw56dVXX02HHHJIbUHj9ddfT1deeWXtF66f/exn6dvf/nbZQwytpVKpVMoeRGR33HFHbYXvjDPOSMcee2yt9sYbb9RWIfr06ZNuueWWsocITWHRokVpyy23TDvttFPtF60uXbzhAe1l+fLlabvttqu9vs2ePbvs4YTmJ1/Jqi9AXbt2fcdvQD169EijRo1Kt956a5o7d26p44Nmcemll6bnnnsuTZo0qRb6XnvttbRixYqyhwUhVF/nNtlkk/Tyyy+XPZTwBL+S/e1vf6utQqy77rrvqO+www61f997770ljQyayw033FCbZ88880z6yEc+Unubt/r/3/nOd2qrEEBjVX+5WrhwYe3jFD/5yU/S73//+7TrrruWPazwfMavZM8++2zaaKON3lV/uzZv3rwSRgXN59FHH01vvfVW2nvvvWsr6qeddlq68cYb03nnnVdbhfj1r39d9hChqRxzzDG1z/RVVVfZ99tvvzR58uSyhxWe4FeyJUuWpDXXXPNd9erbvW+3A6tu8eLFtQ+ZH3bYYf/exVt9IXrzzTdrL04TJkyoba4CGqO6YXH//fevLWD85je/qX3OrzrfKJe3ektWPb6lepzLf3r7radqO7Dq3p5LX/nKV95RP+igg2r/rn6mFmicAQMGpN122y197WtfS9dee23tl6/qrnp7Sssl+JWs+pZu9e3e//R2rboVHlh1b8+lDTfc8B316u75qpdeeqmUcUEU1dW/O++8Mz3yyCNlDyU0wa9kH/vYx2qToHrUxP91++23/7sdWHXVoySqqps7/q+3P0e7wQYblDIuiOLtjy698sorZQ8lNMGvA/wGVP3cw5QpU/5dq771+4tf/KJ2vl91+zuw6r70pS/V/n3hhRe+o/7zn/88devWLQ0bNqykkUFzef75599VW7ZsWfrlL39Z+8jFoEGDShkX/2JzR8mq4a56a5sxY8bUJkv//v3TxRdfnJ588sl3vUABbVe9W8c3vvGNdNFFF9V29w4dOrS2q/eKK66ozT8fq4DGGD16dO1drOpt2jbeeOM0f/78NG3atNrBzWeddVbtKCXK484dHUB1I0f19lG/+tWvap8z2nrrrdPEiRPT8OHDyx4aNJXqqsOpp55aW1GvvsW76aabpsMPP7y2+xBojMsuu6y2cHH//fenF154Ia2zzjq1j1occcQRtdu2US7BDwAgCJ/xAwAIQvADAAhC8AMACELwAwAIQvADAAhC8AMACELwAwAIYqXv3NHS0rJ6RwIl6IjHWJprNCNzDTrGXLPiBwAQhOAHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABDESt+rF6AzGjNmTLbt1FNPLawfffTR2T4/+clPGjIugDJY8QMACELwAwAIQvADAAhC8AMACELwAwAIwq5eYJXtvvvu2bY//vGPqaNasWJFYf2UU07J9rnlllsK67fffnvDxgWwuljxAwAIQvADAAhC8AMACELwAwAIQvADAAhC8AMACMJxLrzLqFGjsm1TpkwprE+ePDnb58gjj2zIuOi45s+fnzqqvfbaq+4+vXr1yrYNHDiwsO44F6AzsOIHABCE4AcAEITgBwAQhOAHABCE4AcAEIRdvU2uX79+2bZp06YV1rfaaqtsn0qlUljfdNNN694h+frrr2f70Lncd999ZQ8h7bnnnoX1T3ziE3U/1rJly7JtL774Yt2PB2VaY401sm09evSo+/GOPfbYwnr37t2zfT772c8W1pcuXZrt89xzzxXWTznllGyfBx54oLC+fPnybJ9orPgBAAQh+AEABCH4AQAEIfgBAAQh+AEABCH4AQAE4TiXJrHBBhsU1mfMmFH3zeZbs2DBgsL6gw8+mO3Tu3fvwvpTTz1V9/Uhp3///oX1bt3q/zF37733Ztuuueaauh8PGnUES+7nadUWW2xRWB87dmy2zx577JEapaWlJdu2ePHiwvpaa61V93X22WefbNsPfvCDwvqJJ55Y93WalRU/AIAgBD8AgCAEPwCAIAQ/AIAgBD8AgCDs6m2CnbtV1113XWF90KBB2T6VSqXuMUyaNKmwPnny5LofCxpp5MiRDXusadOmNeyxoC2+//3vF9ZPOeWUhl5n0aJFhfXnn38+2+eWW24prM+cOTPb57777iusb7XVVtk+3/3udwvr22+/fbbPdtttl23jX6z4AQAEIfgBAAQh+AEABCH4AQAEIfgBAAQh+AEABOE4l05k6tSp2batt966Ydf53Oc+V/exMdAe9t5772zbNttsU/fjvfXWW4X1xx57rO7Hgka6/vrr6/5ZnztmZe7cudk+Tz75ZGH9rrvuSu3h7rvvrvu1qLXjXLbYYovC+oYbbpjt89xzz6VIrPgBAAQh+AEABCH4AQAEIfgBAAQh+AEABGFXbyfazbXjjju2+1igIxkzZky2rVu3+n+c3XHHHYX1P/zhD3U/FjTSbbfdVlg/4IADUmfUvXv3wvqee+6Z7fPpT3+6sL5o0aJsn+9///uF9Wg7d1tjxQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIx7mUZNSoUdm23LEtvXr1yvZZsGBBYb1Pnz51j22DDTaouw800ogRIwrr2267bUOvM2HChIY+HkTW2pFKuWNoLrnkkrqvc/HFF2fbrr766rofLxorfgAAQQh+AABBCH4AAEEIfgAAQQh+AABBtFQqlcpK/cGWltU/mia0//77F9Yvv/zybJ/ctyS3c7dq+PDhhfVx48Zl++y3336F9UcffTTbZ+DAgamZrOTTv12Za/kb1G+//fbttguRxjLXOpf+/ftn23K768ePH5/tM3jw4LrHcNxxxxXWp0yZku2zaNGiFF3lPeaaFT8AgCAEPwCAIAQ/AIAgBD8AgCAEPwCAIAQ/AIAgnGXQAKNGjcq25badd+mSz9xPPPFEYX2vvfbK9pk9e3Zh/eabb872+eIXv1hY79OnT7bPkCFDCuuzZs3K9oEie++9d7btE5/4RMOuc+qpp2bb1l9//cL6TjvtlO1z9NFH1z2GK664orA+derUbJ8lS5bUfR2o18SJEwvro0ePzvbp3bt33cfjtOU4n/e9732FdUe2rBorfgAAQQh+AABBCH4AAEEIfgAAQQh+AABBtFRWcquNm1mnNHTo0ML6jBkzsn169epV99fzd7/7XWF9xIgRqV7PPfdctu39739/Yf3RRx/N9hk4cGBqJm4cX56ZM2dm23beeeeGXefuu+/Otm2//falPi/+8pe/ZNtyu/iXLVuWOiNzrWP69a9/XVg/8MADs33uuuuuwvptt92W7dOzZ8+6T8V46623Cuvjxo3L9jn99NNTdJX3mGtW/AAAghD8AACCEPwAAIIQ/AAAghD8AACCEPwAAIJwnEsdrr766sL65z//+bofq7WvZ+7m9ddee23d11m+fHm2Lfetd5xLuZptrm255ZaF9RtvvDHbp0+fPqnMr3VHeF6cdNJJhfVJkyalzqgjfE2bfa61xRprrFFY7969e7ZP7kihN998M9unS5fidaYDDjig7jmwcOHCbJ8hQ4ak6CqOcwEAoErwAwAIQvADAAhC8AMACELwAwAIolvZA+hohg4dmm3bZZddGnadI488Mtt20003New6ULbRo0eXunO3sxo8eHDZQyCA3A7dXL2tVqxYUVi//PLL6z7h4itf+Uq2z7hx4wrrP/jBD95zjFFY8QMACELwAwAIQvADAAhC8AMACELwAwAIQvADAAgi7HEuuZtz//nPf27odXLHtkyePLldjqHJ3Ri7te31rfWBeg0YMCB1VDfffHPdNzn/29/+Vlg/4ogjUiM9/fTTDX086GxOP/30wvqXv/zlbJ9PfepTq3FEzcErPABAEIIfAEAQgh8AQBCCHwBAEIIfAEAQYXf1Dhw4sO7dfD/96U8L60uWLMn2mTNnTmqUtdZaK9t21FFH1bVzt7W/64QJE9owOij2z3/+s12uk5trF110UbbPpEmTCus77LBDts95552X2sO0adPa5TrQTLbYYovC+oYbbpjt89xzz6VIrPgBAAQh+AEABCH4AQAEIfgBAAQh+AEABCH4AQAE0dTHuXTv3j3bdtxxx9X9eGeffXapx1VstNFG2bYRI0YU1l9++eVsn5kzZxbWr7vuujaMDor95je/Kax/97vfbeh1cse2PPLII9k+99xzT2G9b9++2T69e/dOjXLhhRdm2/7xj3807DrEtu+++2bbbr311sL6/PnzU9k+8IEP1N0n93oc7ciW1ljxAwAIQvADAAhC8AMACELwAwAIQvADAAiiqXf1Hn300dm2kSNH1rXTtWrhwoWpTPvvv3/dfS655JJs21FHHbWKI4L3dvfdd9dVr9puu+3qvs4pp5xSd5+WlpbCeqVSSe2x47i1ObhkyZKGjoG4u3enTp2a7XP66acX1idNmpTaQ8+ePbNtxx9/fN2PN3fu3FUcUfOz4gcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABBEUx/nMmTIkLqPcRg2bFjdN2d/5ZVXUiOddtpphfXjjjuu7sfK/T2hveSOJTnjjDOyfS677LLUUT3xxBN1z8/f/e53hfWlS5c2bFyQO8JsnXXWyfbZfPPNU5mGDh1ad9tLL72U7XPeeec1ZFzNzIofAEAQgh8AQBCCHwBAEIIfAEAQgh8AQBBNvav3wQcfzLbtvvvudT/e2WefXVg///zzG7rjOHfj9tZuHP/QQw8V1idOnFj32KA9XH311dm2n/3sZ4X10aNH132dM888M9u2bNmywvoNN9yQ7XPnnXcW1l9//fW6xwaN9PDDDxfWd95551S2nj17Nuy0iunTp7fpdZ9/seIHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQREultTNC/u8fbGlJnU2/fv2ybXfddVdhfb311kvtobWvZ+4m8JMnT872ueqqqwrrc+bMacPo4ljJp3+76oxzDd6Lubb6DR48uLB+44031n0U2PDhw7N9lixZUlj/+te/nu2z1157Fda/+MUvZvtcdtllhfVvfvOb2T6OVUrvOdes+AEABCH4AQAEIfgBAAQh+AEABCH4AQAE0dS7elszZMiQwvqf//zndrn+TTfdlG3bZ599CuuvvPLKahxRTHYaQvsw18rT2m7bCy+8sLC+YMGCbJ8VK1YU1j/wgQ/U/f2/4YYbsn2OO+64wvq9996b7UOyqxcAgH8R/AAAghD8AACCEPwAAIIQ/AAAghD8AACCCHucC1Q5YgLah7lWnm7dumXbLrroosL6yJEj677OrFmzsm3XXXddYf3MM8/M9lm2bFndYyA5zgUAgH8R/AAAghD8AACCEPwAAIIQ/AAAgrCrl9DsNIT2Ya5B+7CrFwCAGsEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgiJZKpVIpexAAAKx+VvwAAIIQ/AAAghD8AACCEPwAAIIQ/AAAghD8AACCEPwAAIIQ/AAAghD8AACCEPwAAIIQ/AAAghD8AACCEPwAAIIQ/AAAghD8OoAHH3wwHXDAAWnzzTdPvXr1Sr17905DhgxJM2bMKHto0NQmTZqUWlpa0uDBg8seCjSNQw89tDavcv8888wzZQ8xtG5lD4CU5syZk1599dV0yCGHpL59+6bXX389XXnllekLX/hC+tnPfpa+/e1vlz1EaDpPP/10OvXUU9Naa61V9lCgqYwePTrttttu76hVKpV02GGHpX79+qWNN964tLGRUkul+t2gw1m+fHnabrvt0htvvJFmz55d9nCg6Xz5y19OCxYsqM21hQsXpgceeKDsIUHTuvnmm9Muu+xSW2UfO3Zs2cMJzVu9HVTXrl3TJptskl5++eWyhwJNZ9asWWn69Onp7LPPLnsoEMKll15ae5v3oIMOKnso4XmrtwN57bXX0pIlS9Irr7ySrrnmmvT73/8+HXjggWUPC5pKdYXviCOOSN/85jfTVlttVfZwoOktW7Ys/eY3v0k77bRT7a1eyiX4dSDHHHNM7TN9VV26dEn77bdfmjx5ctnDgqZywQUX1D5Xe8MNN5Q9FAjhuuuuSy+88EL66le/WvZQEPw6lqOOOirtv//+ad68ebXfjqorE2+++WbZw4KmUX3xOfHEE9P48ePTBhtsUPZwIMzbvGussUb60pe+VPZQsLmjY9t9991rn/G7/fbba5+NAFbNd77zndpKX/UIpe7du9dqw4YNs7kDVpPFixenDTfcMH3mM59xRFkHYXNHB1Zd/bvzzjvTI488UvZQoNN79NFH05QpU9J//dd/1VbVn3zyydo/1Z3z1c8gVf/7xRdfLHuY0FSuvvrq2hFl3ubtOAS/Dqy60aOqutkDWDXVQ2NXrFhRC36bbbbZv/+prqhXf7mq/veECRPKHiY0lWnTpqW11167di4tHYPP+HUAzz//fOrTp887atUViF/+8pepZ8+eadCgQaWNDZpF9e4cV1111bvq48aNqx2gfs4556QtttiilLFBM6qek1n9aMVXvvKV2l2p6BgEvw5yyvmiRYtqt2mrnmg+f/782m9J1YObzzrrrNpvS8Cqqd4KcZ999nlX/e2z/IragLa7/PLL01tvveVt3g7G5o4O4LLLLksXXnhhuv/++2u7DtdZZ53aXTuqZ41ZHofVy+YOWD0+9alPpccff7z2mdrqTQnoGAQ/AIAgbO4AAAhC8AMACELwAwAIQvADAAhC8AMACELwAwAIQvADAAhipe/c0dLSsnpHAiXoiMdYmms0I3MNOsZcs+IHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhOAHABBEt7IH0Oz69+9fWF9zzTWzfXbffffC+hlnnJEaacCAAYX1xx57rKHXgSJDhw7Nti1durSwfs8992T7vPnmmymCLbfcMtu26667FtZnzZqV7fPggw82ZFxA52DFDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIIiWSqVSWak/2NKy+kfTSX3yk5/Mtl122WWF9Q9+8IPZPitWrEjtYfbs2YX1rbfeOkWxkk//dtUZ59omm2ySbfv85z9fWJ8wYULdc+DDH/5wts+iRYtSBA899FC27SMf+Uhhfd68eW363jWSuQapQ8w1K34AAEEIfgAAQQh+AABBCH4AAEEIfgAAQXQrewCdybBhwwrr5557brZP3759V+OIoPG6dcv/WDjiiCMK6wcffHC2zzbbbFP37vVXX3210+wMXRVduuR/9859TTfffPO6r7PeeuvV3Qc6o+7duxfWR40ale1z/vnnF9ZHjx6d7TNlypTUWVnxAwAIQvADAAhC8AMACELwAwAIQvADAAhC8AMACCLscS6XX3553cdFDBo0qLA+YMCA1Bkde+yxZQ+BDuikk07Kto0dO7Zh17nwwguzbYcddliK4IMf/GC27aKLLqr78RYsWFBY33vvvet+LGik3Ovk+973vmyf9ddfv7C+xx57ZPvk2vr375/tU8m87o8YMSLbx3EuAAB0eIIfAEAQgh8AQBCCHwBAEIIfAEAQLZWVvOt5S0tLKtPhhx+ebWvtRsr17tBt7cbxbdkd+8c//rGw/sADD2T7tGUMjbyZdSQr+fRvV+011/r161dY//Of/5zts+mmmxbWH3vssWyfK6+8srA+ceLEbJ8lS5akZrLhhhsW1i+++OJsn89+9rN1Xye3e/faa69NZYs818p+nn3nO9/J9tloo43q+vnwXm05ffv2LayvtdZapT9nWjLPg9b+nk899dRqHNGqea+vmxU/AIAgBD8AgCAEPwCAIAQ/AIAgBD8AgCAEPwCAILqVcdHWjitpr6NMHn744bq3Qf/0pz+t+6iE3NEYXbp0adgN2Ftr22effeq+DjF89atfrevIltZMnz4923bCCSek6C666KKGHdly4403Ztv++te/1v14NI+f//znhfW99tqr7qNMOsLxO48++mhhvUePHtk+m2yyScPm1Lx581IzsuIHABCE4AcAEITgBwAQhOAHABCE4AcAEESn2dX70EMPZfu01pZz0EEH1d3nox/9aGH90ksvzfbJ7ZBsy9fg/PPPz/Zp7Yb3UM9zpiPs5ms2uZ8dbdHaTsOXXnqpYdeh8znrrLPqfl7svPPOhfWFCxdm+/zjH/8orF933XXZPi+88EKq15/+9KfC+sknn5zt8/3vf7/u64wcObKw/tZbb6VmZMUPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgiJbKSp7dkLuRc1uceOKJ2bbccGbOnJntM2vWrNQexy6ce+65hfVddtml7ut06dKl7uNcWvt73nTTTXWPIfc9feCBB7J9pk+fnppJRzy6pJFzrTW551lrX5NFixYV1jfaaKNsnzfeeCM1k+7duxfW/+d//qfu46Na+zlw7733FtZ32223TnmcS+S5Rtv079+/sH733Xdn+6yzzjqF9b/+9a/ZPru04TW8I3uvuWbFDwAgCMEPACAIwQ8AIAjBDwAgCMEPACCIbmVcdMKECalsl19+eWG9b9++2T477rhjKtOQIUPa1JaT21E4d+7cuh+r2Xb7Ut9zZr311sv2mT9/fmom48aNq+tG722VO8lgk002yfbZeOON6949fN9997VhdLD6jR07trC+9tprZ/ssXry4sP71r3+9YePq7Kz4AQAEIfgBAAQh+AEABCH4AQAEIfgBAAQh+AEABNFSWck7Zzfbzazfeuutum5c32itHa9Q9hhau/7ChQvrqlfts88+hfXHH388lS3yjeNz3+e2fE1++MMfZttOOOGE1EwuueSSwvpBBx2UOqOuXbu2y3UizzXyhg4dmm27/vrr637Ozpgxo67XoWb0XnPNih8AQBCCHwBAEIIfAEAQgh8AQBCCHwBAEGF39eZ2NLZlR+2BBx6YbbvyyitToxx++OHZttGjR9f9eD179iysb7bZZqk9dOvWLZUt8k7D3G661p6z66+/ft3XeeCBBwrrP/3pT1MjzZo1q7A+ZMiQbJ9cW2tzuiM/P1544YXC+n777Vf3163RIs81UlpzzTUL61dffXW2z+67715Ynzt3brbP4MGDC+uLFy9OUVTs6gUAoErwAwAIQvADAAhC8AMACELwAwAIQvADAAgi7HEuv/71rxt25MA555yTbbv99ttTR/XBD36wsH7ppZdm+3zyk59s2PW7d++eyuaIiXfbY489sm1Tp04trG+wwQapbPPmzSus9+3bt+6vdXs9L5YuXZptu/POO+uqV11wwQWF9cceeyyVzVyLbdy4cYX1CRMm1P2cOeGEE7J9fvjDH6boKo5zAQCgSvADAAhC8AMACELwAwAIQvADAAgi7K5eUjr55JML6wMGDMj2ae1m7/Wyq7fzzbWddtqpsP6tb30r22fvvfcurK+11lrZPt26dUvtoZG7elvboXvMMcfUtRO56n//939TMzHXmt+IESPqfj639j347W9/W1j/4he/2IbRxVGxqxcAgCrBDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIx7nU4YADDiisz507N9vntttuS2U666yzsm1HHnlkYX3FihWpPTjOJfZcO+SQQ7JtW265ZbuMYcyYMQ17XrR2c/jWbiofhbnWPHr06FFY/9WvfpXts++++xbWH3rooWyfnXfeubC+aNGi9xxjZBXHuQAAUCX4AQAEIfgBAAQh+AEABCH4AQAEYVfvfxg+fHi27Re/+EXdN2ffddddC+uPP/543WM444wzUr0222yzbFvPnj0L63b1livKXOsIcs/11p4Xt9xyS903qH/55ZdTdOZa8zj55JML6+PHj8/2efXVV+t+XZs0aVIbRkfFrl4AAKoEPwCAIAQ/AIAgBD8AgCAEPwCAIAQ/AIAgupU9gI5m3XXXzbb16dOn7sd75JFHCutdu3bN9lm+fHlqD62NIWfBggV11av22Wefuq8DHdX5559fWHdkC81k3333zbb993//d92Pd8UVVxTWHdnS/qz4AQAEIfgBAAQh+AEABCH4AQAEIfgBAARhV28DbujeWa+T89RTT9W9m+vKK69cjSOCtrOrHOp36KGHZtt69OhRWL/mmmuyfcaOHduQcbHqrPgBAAQh+AEABCH4AQAEIfgBAAQh+AEABCH4AQAE4TiXTmTmzJnZtlmzZtX9eC0tLYX1Bx98MNvHsS10Np/97GfrngPPP/98ts+cOXMaMi7oCCZOnFhYHzFiRLbPa6+9Vli/4IILsn0WLFjQhtGxOljxAwAIQvADAAhC8AMACELwAwAIQvADAAjCrt7/cOutt9a9o/Wpp57K9rnjjjtSo7S223b27NkNuw40k2effTbb9sILLxTWDznkkGyfW265pSHjgvYyYMCAbNuxxx5bWK9UKtk+J554YmH9uuuua8PoaG9W/AAAghD8AACCEPwAAIIQ/AAAghD8AACCEPwAAIJoqbS2Z3slbmYeyQYbbFBYX7p0abbPokWLVuOIWFUr+fRvV+Za+xkyZEhhfdasWe0+lmZnrq1+Xbt2LazfcMMN2T5Dhw4trP/yl7/M9vnWt75VWF+2bNl7jpHy55oVPwCAIAQ/AIAgBD8AgCAEPwCAIAQ/AIAg7OolNDsNoX2Ya6vfsGHDCut/+tOfsn1yO3EHDx6c7fPYY4+1YXS0F7t6AQCoEfwAAIIQ/AAAghD8AACCEPwAAIIQ/AAAguhW9gAAgFV32mmn1d1n/PjxhXVHtjQvK34AAEEIfgAAQQh+AABBCH4AAEEIfgAAQbRUVvLO2c12M2uocuN4aB/mGnSMuWbFDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIIiVPs4FAIDOzYofAEAQgh8AQBCCHwBAEIIfAEAQgh8AQBCCHwBAEIIfAEAQgh8AQBCCHwBAEIIfAEAQgh8AQBCCHwBAEIIfAEAQgh8AQBCCXwewePHidNJJJ6U99tgjrb/++qmlpSVNnTq17GFB01m6dGk6/vjjU9++fVPPnj3TjjvumK6//vqyhwVN5c4770zf+9730kc/+tG01lprpQ996EPpS1/6UnrkkUfKHhqCX8ewcOHCNGHChPTwww+nbbbZpuzhQNM69NBD049//OP01a9+NZ1zzjmpa9euaa+99ko333xz2UODpvGjH/0oXXnllWnXXXetzbNvf/vbadasWenjH/94euCBB8oeXngtlUqlUvYgoquuQrz00kvpAx/4QLrrrrvSJz7xifSLX/yi9iIFNMYdd9xRW+E744wz0rHHHlurvfHGG2nw4MGpT58+6ZZbbil7iNAUqnNp++23T927d/937dFHH01bbbVV2n///dOvfvWrUscXnRW/DmDNNdeshT5g9Zk+fXptha+6+vC2Hj16pFGjRqVbb701zZ07t9TxQbPYaaed3hH6qj784Q/X3vqtvrNFuQQ/IIS//e1vacstt0zrrrvuO+o77LBD7d/33ntvSSOD5ld9c/G5555LvXv3Lnso4Ql+QAjPPvts2mijjd5Vf7s2b968EkYFMUybNi0988wz6cADDyx7KOEJfkAIS5YsqX2s4j9V3+59ux1ovNmzZ6fDDz88fepTn0qHHHJI2cMJT/ADQqge31LdSPWfqhs83m4HGmv+/Pnpc5/7XHrf+97378/ZUq5uJV8foF1U39KtvtVU9BZwVfVsP6BxXnnllbTnnnuml19+Od10003mWAdhxQ8I4WMf+1jtANlFixa9o3777bf/ux1ojOpK+ogRI2pz7tprr02DBg0qe0j8P4IfEEL1/LDly5enKVOm/LtWfeu3emZm9Xy/TTbZpNTxQbOozrPqJo7qMUlXXHFF7bN9dBze6u0gJk+eXFsOf3tn4YwZM9LTTz9d++8jjjii9vkIoO2q4e6AAw5IY8aMSc8//3zq379/uvjii9OTTz6ZLrzwwrKHB03jmGOOSddcc01txe/FF19814HNI0eOLG1suHNHh9GvX780Z86cwrYnnnii1g6s+ttP48ePr70QVe+Ws/XWW6eJEyem4cOHlz00aBrDhg1LM2fOzLaLHeUS/AAAgvAZPwCAIAQ/AIAgBD8AgCAEPwCAIAQ/AIAgBD8AgCAEPwCAIFb6zh0tLS2rdyRQgo54jKW5RjMy16BjzDUrfgAAQQh+AABBCH4AAEEIfgAAQQh+AABBCH4AAEEIfgAAQQh+AABBCH4AAEEIfgAAQQh+AABBCH4AAEEIfgAAQQh+AABBCH4AAEEIfgAAQQh+AABBCH4AAEEIfgAAQQh+AABBCH4AAEEIfgAAQQh+AABBCH4AAEF0K3sAAGU5+OCDC+v9+vWr+7He//73Z9uOPPLIwvqiRYuyfT7zmc8U1u++++66xwaNdNpppxXWjzvuuLofq0uX/PrTihUrCusXXHBBts+UKVMK63//+9/rHluzsuIHABCE4AcAEITgBwAQhOAHABCE4AcAEERLpVKprNQfbGlZ/aMJ5He/+122bc899yysjxgxItvn2muvbci4olnJp3+7MtfaZvPNNy+s/+EPf6i7T0f4Hhx++OF172jsyMy15ti5W3XUUUcV1tdYY42Gfg/a8pxZuHBhXbvkqx566KHUTN7r62bFDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIIhuZQ8gqta2W+fa2nLjeGgmEydOzLYdffTRhfUePXqkzuiEE05oquNcKM/GG2+cbTv44IML68cdd1zdr1Fvvvlmts+cOXMK61265NefPvShD9V9bEzv3r3rPvJs5513Lqw/++yzqRlZ8QMACELwAwAIQvADAAhC8AMACELwAwAIwq7e1axr166F9V69erX7WKCzuO222wrrH//4x+uea+3ljjvuyLbtsMMOdT/emmuuuYojIppBgwYV1mfMmJHts+mmmzbs+meddVa2bfz48XU/3qmnnlr3juO2/D17BXs9tuIHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhONcVrP11luvsD5kyJB2Hwt0JJMmTcq2bbvttu1yZMs999xT97Ex3/jGNwrrf//737N97r777jaMDuozcuTI1X5kS9XYsWML66effnq7XGebbbbJ9hk+fHjd1zn77LML6yNGjEjNyIofAEAQgh8AQBCCHwBAEIIfAEAQgh8AQBB29QKl7N499thjs326dWvcj6b9998/2/bPf/6z7rHdf//9hfU33nijDaODxhk4cOBq31Fb9ZOf/KRh16H9WfEDAAhC8AMACELwAwAIQvADAAhC8AMACELwAwAIwnEuJWlpaam7rbU+UKaJEydm23JHo7TlyJZ58+Zl2772ta8V1m+77bZsnyVLltT1WK0ZMGBA3X2gkc4+++y6n5vTp08vrP/oRz9KUSxYsCBFYsUPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAi7ektSqVTq7vPEE0+slrHAqjrssMOybW3ZvZtzySWXZNv+8pe/NOw60BnNnDmzsD5w4MB2H0tnMmnSpBSJFT8AgCAEPwCAIAQ/AIAgBD8AgCAEPwCAIAQ/AIAgHOfSidx3331lDwHaxfz58wvrU6ZMafexAOXo169fYf1DH/pQtk9LS0th/f7778/2eeWVV1IkVvwAAIIQ/AAAghD8AACCEPwAAIIQ/AAAgrCrtxNZvHhx2UOAdnHxxRcX1p988snUUW222WZlDwGaysCBA+uqV1UqlcL6BRdckO2zcOHCFIkVPwCAIAQ/AIAgBD8AgCAEPwCAIAQ/AIAgBD8AgCAc5wJ0OFOnTk2dzaGHHlr2EKCpjB49umGP1dpxLtFY8QMACELwAwAIQvADAAhC8AMACELwAwAIwq7ekrS0tLSpDcq07777FtbXWWeddh8L0PkNHTo027bLLru061iisOIHABCE4AcAEITgBwAQhOAHABCE4AcAEITgBwAQhONcSlKpVMoeAtRt0003LayvscYaDb3Od7/73cL6mDFjsn2WLFnSsOv36tUr2/bpT3+6sL7TTjulRpo2bVpDHw86ou9973vZtvXWW6/ux5s1a9Yqjqj5WfEDAAhC8AMACELwAwAIQvADAAhC8AMACMKu3k5knXXWyba9+OKL7ToWWJ2OOOKIwvqrr76a7TN+/PiG7d4988wzs31Gjx6d2sPGG2/cLteBMu233351n37x2muvZfv8+Mc/bsi4mpkVPwCAIAQ/AIAgBD8AgCAEPwCAIAQ/AIAgBD8AgCAc57Kade/evWGPNWLEiGzb5MmTG3YdyPnDH/5QWD/llFOyfdZee+2GXX/w4MGpkbbddttSj2x5/PHHs21jx45tlzFAexxBNGXKlIZd56STTsq2zZgxo2HXaVZW/AAAghD8AACCEPwAAIIQ/AAAghD8AACCsKt3Ndt+++3LHgI0zOzZswvrCxcubJddvY227rrrtst1li9fXlgfN25cts9jjz22GkcEjXfwwQdn24YPH1734z300EOF9auuuqrux+L/Z8UPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgCMe5rGabbbZZYb2lpSXbJ9d26aWXNmxc0Eg/+MEP6r45e5cu9f/eufXWW2fbzj///Lofb8SIEWl1H9lS9eMf/7iwfvnllzfs+tCvX7+6n+f77bdfYX3YsGHZPitWrEiN0trPgdZeJ2k7K34AAEEIfgAAQQh+AABBCH4AAEEIfgAAQbRUKpXKSv1Bu2va5JOf/GRh/a9//WvdX+vevXtn+7z44ottGB0r+fRvV80213K7ekeNGpU6o9yOxjPPPDPbZ8yYMSk6c60+gwYNKqxfddVV2T69evUqrG+00UYN/do08nvZluucfPLJ2T6XXHJJYX3OnDkpisp7fH+s+AEABCH4AQAEIfgBAAQh+AEABCH4AQAEIfgBAAThOJfVbLvttius33HHHdk+jnNpP46YWP0GDx5cWP/Tn/6U7dPac71suWNbjj/++HYfS2dirr3bNttsk2377W9/W1jfdNNNU3voyMe5tObhhx8urO+7777ZPnMyR70sW7YsdUaOcwEAoEbwAwAIQvADAAhC8AMACELwAwAIwq7e1ez9739/Yf3555/P9rGrt/3YadjxdvtWjR07trB+4IEHpvbwzDPPZNt22223wvojjzyyGkfU+UWea4MGDSqsz5gxI9unvXbvNnK37YIFC7J9Jk2aVFg/55xz6r5Oo/8+YzM/b370ox+lzsiuXgAAagQ/AIAgBD8AgCAEPwCAIAQ/AIAgBD8AgCAc59IBj3OZPn16YX3kyJHZPp31ZtJli3zEBLQncw3ah+NcAACoEfwAAIIQ/AAAghD8AACCEPwAAIKwq5fQ7DSE9mGuQfuwqxcAgBrBDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIAjBDwAgCMEPACAIwQ8AIIiWSqVSKXsQAACsflb8AACCEPwAAIIQ/AAAghD8AACCEPwAAIIQ/AAAghD8AACCEPwAAIIQ/AAAUgz/HwMu3pU1kvhiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure(figsize=(8,8))\n",
    "\n",
    "cols, rows = 3,3\n",
    "\n",
    "for i in range(1, cols*rows+1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import UNet\n",
    "\n",
    "model = UNet(1, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (down1): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (down2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (down3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (up1): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (up2): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (up3): Sequential(\n",
      "    (0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=18432, out_features=24, bias=True)\n",
      "    (1): Linear(in_features=24, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.382249  [  100/60000]\n",
      "loss: 0.599665  [10100/60000]\n",
      "loss: 0.458707  [20100/60000]\n",
      "loss: 0.275282  [30100/60000]\n",
      "loss: 0.164346  [40100/60000]\n",
      "loss: 0.198263  [50100/60000]\n",
      "loss: 0.207973  [  100/60000]\n",
      "loss: 0.193424  [10100/60000]\n",
      "loss: 0.199400  [20100/60000]\n",
      "loss: 0.125057  [30100/60000]\n",
      "loss: 0.071094  [40100/60000]\n",
      "loss: 0.105533  [50100/60000]\n",
      "loss: 0.146663  [  100/60000]\n",
      "loss: 0.143760  [10100/60000]\n",
      "loss: 0.150486  [20100/60000]\n",
      "loss: 0.102231  [30100/60000]\n",
      "loss: 0.047748  [40100/60000]\n",
      "loss: 0.073087  [50100/60000]\n",
      "loss: 0.112172  [  100/60000]\n",
      "loss: 0.119819  [10100/60000]\n",
      "loss: 0.122224  [20100/60000]\n",
      "loss: 0.094222  [30100/60000]\n",
      "loss: 0.037310  [40100/60000]\n",
      "loss: 0.056248  [50100/60000]\n",
      "loss: 0.089161  [  100/60000]\n",
      "loss: 0.104383  [10100/60000]\n",
      "loss: 0.102208  [20100/60000]\n",
      "loss: 0.090594  [30100/60000]\n",
      "loss: 0.031466  [40100/60000]\n",
      "loss: 0.045696  [50100/60000]\n",
      "loss: 0.073181  [  100/60000]\n",
      "loss: 0.092395  [10100/60000]\n",
      "loss: 0.087332  [20100/60000]\n",
      "loss: 0.087556  [30100/60000]\n",
      "loss: 0.027552  [40100/60000]\n",
      "loss: 0.038458  [50100/60000]\n",
      "loss: 0.061168  [  100/60000]\n",
      "loss: 0.083376  [10100/60000]\n",
      "loss: 0.076091  [20100/60000]\n",
      "loss: 0.084436  [30100/60000]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      5\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 7\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     10\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Desktop/UNet/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UNet/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/UNet/model.py:27\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1(x)\n\u001b[0;32m---> 27\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdown2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown3(x)\n\u001b[1;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup1(x)\n",
      "File \u001b[0;32m~/Desktop/UNet/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UNet/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/UNet/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/UNet/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UNet/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Desktop/UNet/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/UNet/.venv/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    train(train_data_loader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss, correct = 0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        correct/=size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 98.4%, Avg loss: 0.051056 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_data_loader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, file='./model'):\n",
    "    torch.save(model.state_dict(),file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 5. Ground truth: 5\n"
     ]
    }
   ],
   "source": [
    "sample_idx = torch.randint(len(train_data), size= (1,)).item()\n",
    "\n",
    "pred = model(train_data[sample_idx][0].view(1,1,28,28)).argmax(1).item()\n",
    "truth = train_data[sample_idx][1]\n",
    "\n",
    "print(f\"Prediction: {pred}. Ground truth: {truth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.ones(size=(3,2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12., 12.],\n",
       "        [12., 12.],\n",
       "        [12., 12.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.add_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12., 12.],\n",
       "       [12., 12.],\n",
       "       [12., 12.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
